/**
 * HtmlMark v0.1.3 - a markdown parser
 * Copyright (c) 2020-2023, Kiran Parajuli. (GNU Licensed)
 * https://github.com/kiranparajuli589/htmlmark
 */

/**
 * DO NOT EDIT THIS FILE
 * The code in this file is generated from files in ./lib/index.js
 */

const REGEX = {
	HR_LINE: /^\s*[-+*](?:(?:\s[-+*]){2,}|[-+*]{2,})$/g,
	QUOTE: {
		ITEM: /^\s*(?:>\s*)+(?<value>.+)/g,
		EMPTY: /^\s*[>\s]+$/g,
		COUNT: />/g,
		NON_QUOTE: /[^>\s\t]/
	},
	COMMENT: /^\s*<!-{2}\s(?<value>.+)\s-{2}>/g,
	IMAGE: /^\s*!\[(?<alt>.+)]\((?<url>.+)\)/g,
	HEADING: {
		ITEM: /^\s*(?<level>#{1,6})\s+((?<fenceVal>.+)(?=\s+#+\s*$)|(?<val>.+))/g,
		UNDERLINE_1: /^\s*=+$/g,
		UNDERLINE_2: /^\s*-+$/g
	},
	CODE_BLOCK: /^\s*`{3}\s*(?<lang>[a-z]*)$/g,
	LIST: {
		CHECKBOX: /^\s*(?:[-~*]|\d+\.)\s\[(?<check>\s|x)]\s(?<value>.+)/g,
		UNORDERED: /^\s*(?<mark>[-*+])\s(?<value>.+)/g,
		ORDERED: /^\s*(?<count>\d)\.\s(?<value>.+)/g,
		ITEM: /^\s*(?:(?<mark>[-*+])|(?<count>\d+)\.)\s+(\[(?<check>\s|x)]\s+)?(?<value>.+)/g,
		EMPTY: /^\s*(?<mark>[-*+]|(?<count>\d+)\.)(\s\[(?<check>(\s|x))]\s*|\s*)$/g
	},
	PARAGRAPH: {
		LINK: /^\[(?<text>.+?)]\((?<href>\S+)(?:\s['"](?<title>.+)['"])?\)/,
		REF_LINK: /^((?<!!)\[.+?](?!\(.+\))){1,2}/,
		HTML: /^\s*<\/(?<endTag>\w+)>|^\s*<(?<tag>\w+)(?<attrs>\s\w+(=\\?['"].+?['"])?)?>/,
		// eslint-disable-next-line no-useless-escape
		COMPUTED_HTML: "<(?<tag>%s)(?<attrs>\s\w+=\\?['\"].+?['\"])?>(?<content>.+)<\/%s>",
		IMAGE: /^!\[(?<alt>.+)]\((?<href>\S+)(?:\s'(?<title>[^']+)'(\s(?<width>\d+)(\s(?<height>\d+))?)?)?\)/
	},
	HTML: /^\s*<(?<tag>\w+)(?<attrs>\s\w+=\\?['"].+?['"])?>(?<content>.?)/g,
	LINK_REF: {
		DECLARATION: /\s*\[(?<text>.+)]:\s+(?<href>\S+(?:\s'(?<title>.+?)')?)/g,
		WITH_TEXT: /^(?<!!)\[(?<text>.+?)](?!\(.+\))(?<!!)\[(?<ref>.+?)](?!\(.+\))/,
		WITHOUT_TEXT: /^(?<!!)\[(?<ref>.+?)](?!\(.+\))/
	},
	TABLE: {
		ROW: /^\s*(?<!\\)\|(?=(?:.+(?<!\\)\|)+$)|(?!^)(?<cell>.+?)(?<!\\)\|/gy,
		/**
		 * @example |----|-----|------|
		 */
		DASH_LINE: /^\s*\|(?=(?:-{2,}\|)+$)|(?!^)(?<cell>-{2,})\|/gy,
		/**
		 * @example | --- | --- | --- |
		 */
		S_DASH_LINE: /^\s*\|(?=(?:\s-{2,}\s\|)+$)|(?!^)(?<cell>\s-{2,})\s\|/gy,
		/**
		 * @example |:----:|:----:|:----:|
		 */
		COLON_LINE: /^\s*\|(?=(?::-{2,}:\|)+$)|(?!^):(?<cell>-{2,}):\|/gy,
		/**
		 * @example | :---: | :---: | :---: |
		 */
		S_COLON_LINE: /^\s*\|(?=(?:\s:-{2,}:\s\|)+$)|\s(?!^):(?<cell>-{2,}):\s\|/gy,
		CELL: /(?<!\\)(\|)/g
	},
	ESC: {
		GT: /(?<!<\/?\w[^<>]*)>/g,
		LT: /<(?!([a-z/1-6]+>))/g
	},
	ESCAPED: /\\([*_[\]()!~+\\|`#><])/g,
	FRONT_MATTER: {
		BOUNDARY: /^-{3}\s*$/,
		ENTRY: /^\s*(?<key>\w+):\s*(?<value>.*)$/
	},
	NUMBER: /^\d+$/,
	NUMBER_WITH_DECIMAL: /^\d+\.\d+$/,
	BIG_BRACKETED: /^\[.*]$/,
	CURLY_BRACKETED: /^\{.*}$/
};

/**
 * Utilities Store for the Parser
 */
class Utils {
	/**
	 * Checks if the given text matches the given regex
	 *
	 * @param {string} text
	 * @param {RegExp} regex
	 *
	 * @returns {boolean}
	 */
	static testRegex(text, regex) {
		regex.lastIndex = 0;
		return !!regex.test(text)
	}

	/**
	 * Returns the regex matches for the given text
	 *
	 * @param {string} text
	 * @param {RegExp} regex
	 * @returns {RegExpExecArray}
	 */
	static execRegex(text, regex) {
		regex.lastIndex = 0;
		return regex.exec(text)
	}

	/**
	 * Match the given text against the given regex
	 *
	 * @param {string} text
	 * @param {RegExp} regex
	 *
	 * @returns {*[]}
	 */
	static matchRegex(text, regex) {
		let m;
		const matches = [];

		while ((m = regex.exec(text)) !== null) {
			if (m.index === regex.lastIndex) {
				regex.lastIndex++;
			}

			const rGroups = Object.keys(m.groups);

			m.forEach((match, groupIndex) => {
				if (match && groupIndex !== 0) {
					matches.push({
						type: rGroups[groupIndex - 1],
						value: match
					});
				}
			});
		}
		return matches
	}

	/**
	 * Groups the given array of objects by the given key
	 *
	 * @param {Object[]} array - Array of objects to group
	 * @param {string} key - Key to group by
	 *
	 * @returns {Object[]} - Grouped array of objects
	 */
	static groupBy(array, key) {
		const grouped = [];
		array.forEach((item, index) => {
			if (index === 0) {
				grouped.push(item);
			} else {
				const last = grouped[grouped.length - 1];
				if (last[key] === item[key]) {
					last.value += item.value;
				} else {
					grouped.push(item);
				}
			}
		});
		return grouped
	}

	/**
	 *
	 * @param {string} text
	 * @param {RegExp} regex
	 * @returns {{type: string, value: string}[]}
	 */
	static matchRG(text, regex) {
		const matches = Utils.matchRegex(text, regex);

		return Utils.groupBy(matches, "type")
	}

	/**
	 * Returns the index of the nth occurrence of the given character in the given text
	 * If the nth occurrence is not found, -1 is returned
	 *
	 * @param {string} text - Text to search in
	 * @param {number} position - Position of the nth occurrence
	 * @param {string} delimiter - Character to search for
	 *
	 * @returns {number}
	 */
	static getNthIndex(text, position, delimiter = ">") {
		let count = 0;
		for (let i = 0; i < text.length; i++) {
			if (text[i] === delimiter) {
				count++;
				if (count === position) {
					return i
				}
			}
		}
		return -1
	}
	/**
	 * Finds number of consecutive characters in a string from a given index
	 *
	 * @param {String} str - String to search
	 * @param {Number} cursor - Index to start from
	 * @param {string} char - Character to search for
	 *
	 * @returns {String}
	 */
	static findConsecutive(str, cursor, char) {
		let consecutive = 0;
		for (let i=cursor; i<str.length; i++) {
			if (str[i] === char) {
				consecutive++;
			} else {
				break
			}
		}
		return char.repeat(consecutive)
	}
	/**
	 * Checks if the provided string contains an exact match for the provided identifier
	 *
	 * Generates regex like: /(?<![\\*])\*{2}(?!\*)/ for "**" as identifier
	 *
	 * Returns the index of the found identifier, or -1 if not found
	 *
	 * @param {String} str
	 * @param {String} identifier
	 *
	 * @returns {Number}
	 */
	static isExactMatch(str, identifier) {
		const count = identifier.length;
		const iChar = identifier[0];

		const exactRegex = new RegExp("(?<![\\\\" +
			`${iChar}` +
			"])\\" +
			`${iChar}` +
			`{${count}}` +
			"(?!\\" +
			`${iChar}` +
			")");

		return str.search(exactRegex)
	}

	/**
	 * Checks if the provided string contains an loose match for the provided identifier
	 *
	 * Generates regex like: /(?<!\\)\*{2}/ where * is the identifier
	 *
	 * Returns the index of the found identifier, or -1 if not found
	 *
	 * @param {String} str
	 * @param {String} identifier
	 *
	 * @returns {Number}
	 */
	static isLooseMatch(str, identifier) {
		const iChar = identifier[0];
		const count = identifier.length;

		const regex = new RegExp(
			`(?<![\\\\${iChar}])` +
			`\\${iChar}` +
			`{${count}}`
		);
		return str.search(regex)
	}
}

class Esc {
	static nonTags(str) {
		if (!str) return str
		return str
			.replaceAll("&", "&amp;")
			.replaceAll(REGEX.ESC.LT, "&lt;")
			.replaceAll(REGEX.ESC.GT, "&gt;")
			.replaceAll("\"", "&quot;")
			.replaceAll("'", "&#39;")
	}

	static everything(str) {
		if (!str) return str
		return str
			.replaceAll("&", "&amp;")
			.replaceAll(">", "&gt;")
			.replaceAll("<", "&lt;")
			.replaceAll("\"", "&quot;")
			.replaceAll("'", "&#39;")
	}

	static decode(str) {
		if (!str) return str
		return str
			.replaceAll("&amp;", "&")
			.replaceAll("&gt;", ">")
			.replaceAll("&lt;", "<")
			.replaceAll("&quot;", "\"")
			.replaceAll("&#39;", "'")
	}

	static unEscape(str) {
		if (!str) return str
		if (Utils.testRegex(str, REGEX.ESCAPED)) {
			str = str.replaceAll(REGEX.ESCAPED, "$1");
		}
		return str
	}
}

const TOKENS = {
	NEW_LINE: "new-line",
	PARAGRAPH: "paragraph",
	CODE_BLOCK: "code-block",
	COMMENT: "comment",
	IMAGE: "image",
	QUOTE: "quote",
	BOLD: "bold",
	ITALIC: "italic",
	UNDERLINE: "underline",
	STRIKE_THROUGH: "strike-through",
	CODE: "code",
	LINK: "link",
	LIST: "list",
	LIST_ITEM: "list-item",
	COUNT_ITEM: "count-item",
	CHECK_ITEM: "check-item",
	HEADING: "heading",
	TEXT: "text",
	HR_LINE: "hr-line",
	TABLE: "table", UNORDERED_ITEM: "unordered",
	ORDERED_ITEM: "ordered",
	QUOTE_SEPARATOR: "q-sep",
	LINES: "lines",
	HTML: "html",
	FRONT_MATTER: "front-matter"
};

/**
 * checks if number is in the given range
 * @param {number} a
 * @param {number} b
 * @returns {boolean}
 */
Number.prototype.inRange = function (a, b) {
	return this >= a && this <= b
};

const INDENT_SIZE = 2;


/**
 * Markdown Indentation
 */
class Indent {
	/**
	 * returns the indentation count of the given text
	 *
	 * @param {string} text
	 *
	 * @returns {number}
	 */
	static raw(text) {
		if (["", "\n", undefined].includes(text)) return 0
		let count = 0;
		while (text[count] === " " || text[count] === "\t") {
			count++;
		}
		return count
	}

	/**
	 * calculates the indentation of the given value
	 *
	 * @param {number} rawIndent
	 *
	 * @returns {number}
	 */
	static calc(rawIndent) {
		return Math.floor(rawIndent / INDENT_SIZE) * INDENT_SIZE
	}

	/**
	 * returns the calculated indentation of the given text
	 *
	 * @param {string} text
	 *
	 * @returns {number}
	 */
	static get(text) {
		return this.calc(this.raw(text))
	}

	/**
	 * returns if in the range of the given indentation
	 *
	 * @param {number} test the indentation to test
	 * @param {number} indent the indentation to test against
	 *
	 * @returns {boolean}
	 */
	static inRange(test, indent) {
		return test.inRange(
			(indent-INDENT_SIZE < 0) ? 0 : indent-INDENT_SIZE,
			indent+INDENT_SIZE
		)
	}
}

/**
 * Table Tokenizer
 */
class Table {
	#lines
	#start
	#cursor
	#indent
	#cellCount
	#rows = []
	#lex
	#linkRefs
	#withHeading

	static tokenName = TOKENS.TABLE

	/**
	 * Checks if the given text matches the Table Row regex
	 *
	 * @param {String} text - Text to check
	 *
	 * @returns {boolean}
	 */
	static #testRow(text) {
		return Utils.testRegex(text, REGEX.TABLE.ROW)
			&& !(
				Utils.testRegex(text, REGEX.TABLE.DASH_LINE) ||
				Utils.testRegex(text, REGEX.TABLE.COLON_LINE) ||
				Utils.testRegex(text, REGEX.TABLE.S_DASH_LINE) ||
				Utils.testRegex(text, REGEX.TABLE.S_COLON_LINE)
			)
	}

	/**
	 * Returns the number of cells in a row
	 *
	 * @param {string} text - Line to check
	 *
	 * @returns {number}
	 */
	static #getCellCount(text) {
		return (text.match(REGEX.TABLE.CELL) || []).length
	}

	/**
	 * check if line is a table 'heading - body' separator
	 *
	 * @param {string} text
	 * @param {number} count
	 * @param {number} indent
	 *
	 * @returns {boolean}
	 */
	static #isHBSep(text, count, indent) {
		return Indent.get(text) === indent &&
			(
				Utils.testRegex(text, REGEX.TABLE.DASH_LINE) ||
				Utils.testRegex(text, REGEX.TABLE.COLON_LINE) ||
				Utils.testRegex(text, REGEX.TABLE.S_DASH_LINE) ||
				Utils.testRegex(text, REGEX.TABLE.S_COLON_LINE)
			) &&
			Table.#getCellCount(text) === count
	}

	/**
	 * Checks if the given line is a row of the table
	 *
	 * @param {string} text - Line to check
	 * @param {Number} count - Number of cells in the row
	 * @param {Number} indent - Indentation of the line
	 *
	 * @returns {boolean}
	 */
	static #isRow(text, count, indent) {
		return Indent.get(text) === indent &&
			Table.#testRow(text) &&
			Table.#getCellCount(text) === count &&
			!Table.#isHBSep(text, count, indent)
	}

	/**
	 * Tokenizes a cell of the table
	 *
	 * @param {String} row - Row to tokenize
	 * @param {Array} linkRefs
	 *
	 * @returns {{raw: String, value: String}[]}
	 */
	static #tokenizeCell(row, linkRefs) {
		const strippedRow = row.trim().slice(1, -1);
		const rawCells = strippedRow.split(REGEX.TABLE.CELL);

		const cells = [];

		rawCells.forEach(cell => {
			if (cell === "|") return
			cells.push({
				raw: cell,
				tokens: Paragraph$1.tokenize(cell.trim(), linkRefs)
			});
		});

		return cells
	}

	/**
	 * Checks if the lines from the given cursor contains a table
	 *
	 * @returns {boolean}
	 */
	static test({ lines, cursor, indent }) {
		const lineToParse = lines[cursor];

		if (!Table.#testRow(lineToParse)) return false

		const cellCount = this.#getCellCount(lineToParse);
		let nextLine = lines[cursor + 1];
		let nextNextLine = lines[cursor + 2];

		if (nextLine !== undefined) {
			nextLine = nextLine.trimEnd();
			nextNextLine = nextNextLine?.trimEnd();

			if (
				(
					nextNextLine
					&& Table.#isHBSep(nextLine, cellCount, indent)
					&& Table.#isRow(nextNextLine, cellCount, indent)
				)
				|| Table.#isRow(nextLine, cellCount, indent)
			) {
				return true
			}
		}
		return false
	}

	/**
	 * Runs checks to find the actual end of the table
	 */
	#findEnd() {
		// now the line at the cursor is the first line of the table
		// first we determine if the second line is a table heading/body separator or not
		// if it is, then we know that the table has a heading
		// if it is not, then we know that the table does not have a heading

		this.#cursor += 1;
		if (Table.#isHBSep(this.#lines[this.#cursor], this.#cellCount, this.#indent)) {
			this.#cursor += 2;
			this.#withHeading = true;
		}

		while (
			this.#lines[this.#cursor] !== undefined &&
			Table.#isRow(this.#lines[this.#cursor], this.#cellCount, this.#indent)
		) {
			this.#cursor++;
		}
		this.#lex["withHeading"] = this.#withHeading;
	}

	/**
	 * Table Tokenizer Constructor
	 *
	 * @param {String[]} lines
	 * @param {Number} cursor
	 * @param {Number} indent
	 * @param {Array} linkRefs
	 *
	 * @returns {Table}
	 */
	constructor(lines, cursor, indent, linkRefs) {
		this.#lines = lines;
		this.#cursor = cursor;
		this.#start = cursor;
		this.#indent = indent;
		this.#linkRefs = linkRefs;
		this.#cellCount = Table.#getCellCount(this.#lines[this.#cursor]);
		this.#lex = { type: TOKENS.TABLE, indent: this.#indent, rows: [] };
		this.#withHeading = false;
	}

	/**
	 * Set the rows of the table to the #rows array
	 */
	#setRows() {
		const headingLine = this.#lines[this.#start];

		if (this.#withHeading) {
			this.#rows = (this.#cursor === this.#start + 3)
				? [headingLine, this.#lines[this.#start + 2]]
				: [...[headingLine], ...this.#lines.slice(this.#start + 2, this.#cursor)];
		} else {
			this.#rows = this.#lines.slice(this.#start, this.#cursor);
		}
	}

	/**
	 * Tokenizes cells for each table rows
	 */
	#performDeepLex() {
		this.#rows.forEach(row => {
			this.#lex.rows.push(Table.#tokenizeCell(row, this.#linkRefs));
		});
	}

	/**
	 * Tokenizes the lines for the Table token
	 *
	 * @returns {{cursor: number, lexer: {indent, type: string, rows: *[]}}}
	 */
	tokenize() {
		this.#findEnd();

		this.#setRows();

		this.#performDeepLex();

		return { lexer: this.#lex, cursor: this.#cursor - 1 }
	}

	/**
	 * Runs the HTML parsing for the Table token
	 *
	 * @param {Object} lexer - the Table lexer
	 *
	 * @returns {string} - the Table HTML
	 */
	static parse(lexer) {
		let tHeadingHtml, tBody;
		if (lexer.withHeading) {
			const tHeading = lexer.rows[0];
			tHeadingHtml = `<th>${tHeading.map(t => Paragraph$1.parse(t)).join("</th><th>")}</th>`;
			tBody = lexer.rows.slice(1);
		} else {
			tBody = lexer.rows;
		}
		const tBodyHtml = tBody.map(row => `<tr><td>${row.map(cell => Paragraph$1.parse(cell)).join("</td><td>")}</td></tr>`).join("");
		return `<table>${tHeadingHtml ? `<thead><tr>
    ${tHeadingHtml}
  </tr></thead>` : ""}
  <tbody>
    ${tBodyHtml}
  </tbody>
</table>`
	}
}

class Image {
	static tokenName = TOKENS.IMAGE

	/**
	 * @returns {boolean}
	 */
	static test({ line }) {
		return Utils.testRegex(line, REGEX.IMAGE)
	}

	/**
	 * @param {string} text
	 *
	 * @returns {RegExpExecArray}
	 */
	static match(text) {
		return Utils.execRegex(text.trim(), REGEX.IMAGE)
	}

	/**
	 * @param {string} text
	 *
	 * @returns {{[p: string]: string}}
	 */
	static tokenize(text) {
		return Image.match(text).groups
	}

	/**
	 * returns HTML for image
	 * @param {{url: string, alt: string}} lexer
	 * @returns {string}
	 */
	static parse(lexer) {
		return `<img src='${lexer.url}' alt='${Esc.nonTags(lexer.alt)}'>`
	}
}

class Comment {
	static tokenName = TOKENS.COMMENT

	/**
	 * @returns {boolean}
	 */
	static test({ line }) {
		return Utils.testRegex(line, REGEX.COMMENT)
	}
	/**
	 * @param {string} text
	 *
	 * @returns {RegExpExecArray}
	 */
	static match(text) {
		return Utils.execRegex(text.trim(), REGEX.COMMENT)
	}

	/**
	 * @param {string} text
	 *
	 * @returns {{[p: string]: string}}
	 */
	static tokenize(text) {
		return Comment.match(text).groups
	}

	/**
	 * returns HTML for comment
	 *
	 * @param {{value: string}} lexer
	 *
	 * @returns {string}
	 */
	static parse(lexer) {
		return `<!-- ${lexer.value}-->`
	}
}

/**
 * Horizontal Line
 */
class HrLine {
	static tokenName = TOKENS.HR_LINE

	/**
	 * @returns {boolean}
	 */
	static test({ line }) {
		return Utils.testRegex(line, REGEX.HR_LINE)
	}

	/**
	 * returns HTML for horizontal line
	 *
	 * @returns {string}
	 */
	static parse() {
		return "<hr>"
	}
}

class CodeBlock {
	#lines
	#start
	#cursor
	#indent
	#rawIndent
	#withBraces
	#lang
	#body
	#raw
	#isBroken = false

	static tokenName = TOKENS.CODE_BLOCK

	/**
	 * Checks if the given text is of the CodeBlock type
	 *
	 * @returns {boolean}
	 */
	static test({ line, indent, fromToken, lastLexer }) {
		if (
			!fromToken &&
			indent >= 4 &&
			(!lastLexer || lastLexer.type === TOKENS.NEW_LINE)
		) {
			return true
		}

		// under deep condition inside list item
		// cb needs to be indented at least twice
		if (
			fromToken === TOKENS.LIST_ITEM && indent >= 8 &&
			(!lastLexer || lastLexer?.type === TOKENS.NEW_LINE)
		) {
			return true
		}


		// under deep condition inside quote
		// cb needs regular indentation

		if (
			fromToken === TOKENS.QUOTE && indent >= 4 &&
			(!lastLexer || lastLexer?.type === TOKENS.NEW_LINE)
		) {
			return true
		}

		return CodeBlock.testRegex(line)
	}

	/**
	 * Checks if the given string matches the CodeBlock regex
	 *
	 * @param {String} text - Text to be checked
	 *
	 * @returns {boolean}
	 */
	static testRegex(text) {
		return Utils.testRegex(text.trimEnd(), REGEX.CODE_BLOCK)
	}

	/**
	 * Returns the CodeBlock regex match for the given text
	 *
	 * @param {String} text - Text to be checked
	 *
	 * @returns {RegExpExecArray}
	 */
	static matchRegex(text) {
		return Utils.execRegex(text.trimEnd(), REGEX.CODE_BLOCK)
	}

	/**
	 * The CodeBlock Tokenizer Constructor
	 *
	 * @param {String[]} lines - Lines of the text
	 * @param {Number} cursor - Cursor position to start from
	 * @param {Number} indent - Calculated Indent of the text
	 * @param {Number} rawIndent - Raw indent of the text
	 *
	 * @returns {CodeBlock}
	 */
	constructor(lines, cursor, indent, rawIndent) {
		this.#lines = lines;
		this.#cursor = cursor;
		this.#start = cursor;
		this.#indent = indent;
		this.#rawIndent = rawIndent;
		this.#withBraces = CodeBlock.testRegex(lines[cursor]);
		this.#lang = CodeBlock.matchRegex(lines[cursor])?.groups?.lang || null;
	}

	/**
	 * Finds the end of the CodeBlock
	 *
	 * Checks if the CodeBlock is broken or not
	 */
	#findEnd() {
		let nextLine, nextLineIndent, nextLineMatch, isNextLineClosingOne;

		do {
			nextLine = this.#lines[++this.#cursor];
			if (nextLine === "") {
				continue
			}
			nextLineIndent = (nextLine) ? Indent.get(nextLine) : null;

			if (nextLine !== undefined) {
				if (this.#withBraces) {
					nextLineMatch = nextLine.trim() === "```";
					if (
						nextLineMatch &&
						nextLineIndent === this.#indent
					) {
						isNextLineClosingOne = true;
					}
				}
			}

			if (!isNextLineClosingOne) {
				if (nextLineIndent < this.#indent) {
					isNextLineClosingOne = true;
					if (this.#withBraces) this.#isBroken = true;
				}
			}

		} while (
			nextLine !== undefined &&
			!isNextLineClosingOne
		)
	}

	/**
	 * Sets the CodeBlock body
	 */
	#setBody() {
		const start = (this.#withBraces) ? this.#start + 1 : this.#start;

		this.#body = this.#lines.slice(start, this.#cursor)
			.map(line => line.slice(Math.min(this.#rawIndent, Indent.raw(line))))
			.join("\n");
	}

	/**
	 * Sets the CodeBlock raw body
	 */
	#setRaw() {
		let endRaw;
		if (this.#withBraces) {
			endRaw = this.#cursor + 1;
			if (this.#isBroken) endRaw = this.#cursor;
		} else endRaw = this.#cursor;
		this.#raw = this.#lines.slice(this.#start, endRaw).join("\n");
		this.#cursor = endRaw;
	}

	/**
	 * Tokenizes the lines for the CodeBlock token
	 *
	 * @returns {{
	 * cursor: number,
	 * lexer: {
	 * 		type: string,
	 * 		indent: number,
	 * 		language: string|null,
	 * 		value: string,
	 * 		raw: string
	 * }}}
	 */
	tokenize() {
		this.#findEnd();

		this.#setBody();

		this.#setRaw();

		return {
			cursor: this.#cursor - 1,
			lexer: {
				type: TOKENS.CODE_BLOCK,
				indent: this.#indent,
				language: this.#lang || null,
				value: this.#body,
				raw: this.#raw
			}
		}
	}

	/**
	 * returns HTML for code block
	 *
	 * Format: <pre><code>{body}</code></pre>
	 *
	 * @param {Object} lexer - the CodeBlock lexer
	 * @param {Function|null} highlightFn - A function to highlight code blocks
	 *
	 * @returns {string} - the CodeBlock HTML
	 */
	static parse(lexer, highlightFn = null) {
		let skeleton = "<pre><code%class>%s</code></pre>";
		if (lexer.language) {
			skeleton = skeleton.replace("%class", ` class='language-${lexer.language}'`);
		} else {
			skeleton = skeleton.replace("%class", "");
		}
		if (highlightFn) {
			const highlightedCode = highlightFn(lexer.value, lexer.language);
			if (typeof highlightedCode === "string") {
				lexer.value = highlightedCode;
			} else {
				console.error("highlightFn must return a string");
				console.info("highlightFn was not used");
			}
			skeleton = skeleton.replace("%s", lexer.value);
		} else {
			skeleton = skeleton.replace("%s", Esc.everything(lexer.value));
		}
		return skeleton
	}
}

class Parser {
	#lexers
	#cursor
	#config
	#fromToken
	#currentLexer
	#parsedContent
	#modifiedParsers = {}

	constructor(lexers, { from = null, config = {} } = {}) {
		this.#lexers = lexers;
		this.#parsedContent = [];
		this.#fromToken = from;
		this.#config = config;
		this.#modifiedParsers = {};

		this.#modifiedParsers[TOKENS.PARAGRAPH] = this.#parseParagraph.bind(this);
	}

	#parseParagraph() {
		let parsed = Parsers.Paragraph.parse(this.#currentLexer);
		if (this.#fromToken === TOKENS.LIST) {
			this.#parsedContent.push(`${parsed}`);
		} else this.#parsedContent.push(`<p>${parsed}</p>`);
	}


	#parseCurrentLexer() {
		for (const module in Parsers) {
			if (Parsers[module].tokenName === this.#currentLexer.type) {
				if (this.#modifiedParsers[this.#currentLexer.type]) {
					this.#modifiedParsers[this.#currentLexer.type]();
					return
				}

				if (
					this.#currentLexer.type === TOKENS.CODE_BLOCK &&
					this.#config.highlightFn &&
					typeof this.#config.highlightFn === "function"
				) {
					this.#parsedContent.push(Parsers[module].parse(this.#currentLexer, this.#config.highlightFn));
					return
				}

				this.#parsedContent.push(Parsers[module].parse(this.#currentLexer));
				return
			}
		}
	}

	run() {
		for (this.#cursor=0; this.#cursor<this.#lexers.length; this.#cursor++) {
			this.#currentLexer = this.#lexers[this.#cursor];
			this.#parseCurrentLexer();
		}

		// remove any %s leftovers and return
		return this.#parsedContent
			.map(item => item.replaceAll("%s", ""))
			.join("")
	}
}

class Quote {
	#lines
	#start
	#cursor
	#body = []
	#tBody = []
	#cDepth
	// these items should break the quote
	#breakTokens = [
		// TODO: for heading, we may have to
		//  check for underlined headings too
		REGEX.HEADING.ITEM,
		REGEX.LIST.ITEM,
		REGEX.CODE_BLOCK
	]

	static tokenName = TOKENS.QUOTE

	/**
	 * Checks if the given text matches the Quote regex
	 *
	 * @returns {boolean}
	 */
	static test({ line }) {
		return Utils.testRegex(line, REGEX.QUOTE.ITEM)
	}

	/**
	 * Checks if the given text matches the Empty Quote regex
	 *
	 * @param {string} text
	 *
	 * @returns {boolean}
	 */
	static testEmpty(text) {
		return Utils.testRegex(text, REGEX.QUOTE.EMPTY)
	}

	/**
	 * Returns the depth of the quote
	 *
	 * If the text does not start with > i.e. the lazy items, then 0 is returned
	 * Otherwise, the count of > before the first non > character is returned
	 *
	 * @param {string} text
	 *
	 * @returns {number}
	 */
	static getDepth(text) {
		text = text.trimStart();
		if (text[0] !== ">") return 0
		if (Quote.testEmpty(text.trim())) return text.match(REGEX.QUOTE.COUNT).length
		const quotePart = text.substring(0, text.search(REGEX.QUOTE.NON_QUOTE));
		return quotePart.match(REGEX.QUOTE.COUNT).length
	}

	/**
	 * Returns the value of the quote from the provided depth
	 *
	 * @param {string} text - the text to be parsed
	 * @param depth - the depth of the quote
	 *
	 * @returns {string}
	 */
	static getValue(text, depth) {
		text = text.trimStart();
		const cursor = Utils.getNthIndex(text, depth);
		// +1 for the ">" character
		return text.substring(cursor + 1)
	}

	constructor(lines, cursor) {
		this.#lines = lines;
		this.#cursor = cursor;
		this.#start = cursor;
	}

	#findLazyEnd() {
		this.#cursor--;

		let nextLine;
		// check for laziness
		let endLazy = false;
		do {
			nextLine = this.#lines[++this.#cursor];
			if (nextLine !== undefined) {
				if (Newline$1.test({ line: nextLine })) {
					endLazy = true;
				}
				for (let r=0; r<this.#breakTokens.length; r++) {
					if (Utils.testRegex(nextLine, this.#breakTokens[r])) {
						endLazy = true;
						break
					}
				}
			}
		} while (nextLine !== undefined && !endLazy)


		this.#cursor--;
	}

	/**
	 * Finds the end of the quote
	 *
	 * Runs check for laziness and breaks
	 */
	#findEnd() {
		let nextLine = this.#lines[this.#cursor];
		let nextLineMatch;

		do {
			nextLine = this.#lines[++this.#cursor];
			if (nextLine !== undefined) {
				nextLineMatch = nextLine.trim().startsWith(">");
			} else nextLineMatch = false;
		} while (
			nextLineMatch
			// nextLineIndent === indent
		)

		// here we have formal end of the quote
		// keeping beside the laziness
		// if the last item of the quote is a quote separator
		// then no laziness is allowed
		const lastLineOfQuote = this.#lines[this.#cursor - 1];
		if (Quote.testEmpty(lastLineOfQuote)) {
			this.#cursor--;
			return
		}

		this.#findLazyEnd();
	}

	/**
	 * Calculates the common depth for the Quote
	 */
	#calcCommonDepth() {
		this.#body.forEach((item) => {
			const currDepth = Quote.getDepth(item);
			if (this.#cDepth === undefined) {
				this.#cDepth = currDepth;
			} else if (currDepth !== 0) { // bypass lazy items
				this.#cDepth = Math.min(this.#cDepth, currDepth);
			}
		});
	}


	/**
	 * Sets the body of the quote
	 */
	#setBody() {
		this.#body = this.#lines.slice(this.#start, this.#cursor + 1);
	}

	/**
	 * Trims the quote from the body
	 * Every common depth quote part is stripped
	 */
	#trimBody() {
		this.#body.forEach((item) => {
			if (Quote.test({ line: item }) || Quote.testEmpty(item)) {
				this.#tBody.push(Quote.getValue(item, this.#cDepth).trimEnd());
			} else {
				// the lazy items can be non-quote so no need to get quote value
				this.#tBody.push(item.trimEnd());
			}
		});
	}

	/**
	 * Tokenizes the lines for the Quote token
	 *
	 * @returns {{ cursor: number, lexer: { tokens: Lexer[], depth: number, raw: string } }}
	 */
	tokenize() {
		this.#findEnd();

		this.#setBody();

		this.#calcCommonDepth();

		this.#trimBody();

		const lex = new Lexer$1(this.#tBody, { from: TOKENS.QUOTE });

		return {
			cursor: this.#cursor,
			lexer: {
				type: TOKENS.QUOTE,
				tokens: lex.run(),
				depth: this.#cDepth,
				raw: this.#body.join("\n")
			}
		}
	}

	/**
	 * Wraps the body of the quote inside the Quote HTML tag
	 *
	 * @param {number} depth - the depth of the quote
	 * @param {string} content - the body of the quote
	 *
	 * @returns {string} - the HTML quote
	 */
	static #wrapInside(depth, content) {
		let qHtml = "%s";
		for (let j=0; j<depth; j++) {
			qHtml = qHtml.replace("%s", `<blockquote>
%s</blockquote>`);
		}
		return qHtml.replace("%s", `${content}`)
	}

	/**
	 * Runs the HTML parsing for the Quote token
	 *
	 * @param {Object} lexer - the Quote lex
	 *
	 * @returns {string} - the HTML quote
	 */
	static parse(lexer) {
		const qParts = [];
		lexer.tokens.forEach(qTokens => {
			let babyParser;
			babyParser = new Parser([qTokens]);
			qParts.push(babyParser.run());
		});
		return Quote.#wrapInside(
			lexer.depth,
			qParts.join("")
		)
	}
}

/**
 * Heading Tokenizer
 */
class Heading {
	#line
	#nextLine
	#level
	#match
	#setext = false

	static tokenName = TOKENS.HEADING

	/**
	 * Checks if the given text matches the Heading regex
	 *
	 * @param {string} text
	 * @returns {boolean}
	 */
	static testRegex(text) {
		return Utils.testRegex(text, REGEX.HEADING.ITEM)
	}

	/**
	 * Checks if the given text is of Heading 1 underline type
	 *
	 * @param {string} text
	 * @returns {boolean}
	 */
	static testH1UnderlineRegex(text) {
		return Utils.testRegex(text, REGEX.HEADING.UNDERLINE_1)
	}

	/**
	 * Checks if the given text is of Heading 2 underline type
	 *
	 * @param {string} text
	 *
	 * @returns {boolean}
	 */
	static testH2UnderlineRegex(text) {
		return Utils.testRegex(text, REGEX.HEADING.UNDERLINE_2)
	}

	/**
	 * Returns the regex groups match for the Heading token
	 *
	 * Following groups are returned:
	 * 1. level - number of #s in the Heading
	 * 2. fenceVal - If fenced Heading, the value of the fenced Heading
	 * 3. val - the value of the normal Heading (without fence)
	 *
	 * @param {string} text
	 *
	 * @returns {RegExpExecArray}
	 */
	static match(text) {
		return Utils.execRegex(text, REGEX.HEADING.ITEM)
	}

	/**
	 * Checks if the given text is of Heading type
	 *
	 * @returns {boolean}
	 */
	static test({ line, nextLine }) {
		if (Heading.testRegex(line)) return true
		if (nextLine !== undefined && !HrLine.test({ line })) {
			if (
				Heading.testH1UnderlineRegex(nextLine) ||
				Heading.testH2UnderlineRegex(nextLine)
			) {
				return true
			}
		}
	}

	/**
	 * Heading Tokenizer Constructor
	 *
	 * @param {string} line current line to tokenize
	 * @param {string| undefined} nextLine next line for tokenization
	 *
	 * @returns {Heading}
	 */
	constructor(line, nextLine) {
		this.#line = line;
		this.#nextLine = nextLine;
		this.#findType();
	}

	/**
	 * Checks if the Heading is of Setext or ATX type
	 *
	 * Sets the #setext property to true if it is of Underline type
	 * Sets the #level property to the level of the Heading
	 *
	 * @returns void
	 */
	#findType() {
		if (this.#nextLine !== undefined) {
			if (!Heading.testRegex(this.#line)) {
				if (Heading.testH1UnderlineRegex(this.#nextLine)) {
					this.#setext = true;
					this.#level = 1;
				}
				else if (Heading.testH2UnderlineRegex(this.#nextLine)) {
					this.#setext = true;
					this.#level = 2;
				}
			}
		}
		if (!this.#setext) {
			this.#match = Heading.match(this.#line)?.groups;
			this.#match.value = this.#match.fenceVal || this.#match.val;
			delete this.#match.fenceVal;
			delete this.#match.val;
		}
	}

	/**
	 * tokenizes the line for Heading token
	 *
	 * @returns {{level: number, value: string, raw: string, setext: boolean}}
	 */
	tokenize() {
		if (!this.#setext) {
			return {
				level: this.#match.level.length,
				value: this.#match.value.trimEnd(),
				raw: this.#line,
				setext: false
			}
		} else {
			return {
				level: this.#level,
				value: this.#line.trimEnd(),
				raw: `${this.#line}\n${this.#nextLine}`,
				setext: true
			}
		}
	}

	/**
	 * Runs the HTML parsing for the Heading token
	 *
	 * @param {Object} lexer the Heading lex
	 *
	 * @returns {string} the Heading HTML
	 */
	static parse(lexer) {
		return `<h${lexer.level}>${Paragraph$1.parse(lexer)}</h${lexer.level}>`
	}
}

/**
 * List Tokenizer
 */
class List {
	#lines
	#cursor
	#indent
	#body = []
	#end
	#shrunkBody = []
	#lex
	#match
	#isEmpty
	#meta = {
		checklist: false,
		ordered: false,
		identifier: null
	}

	static tokenName = TOKENS.LIST

	static testEmpty(text) {
		return Utils.testRegex(text, REGEX.LIST.EMPTY)
	}

	static testItem(text) {
		return Utils.testRegex(text, REGEX.LIST.ITEM)
	}

	static test({ line }) {
		if (List.testEmpty(line)) { return true }
		return List.testItem(line)
	}


	static matchEmpty(text) {
		return Utils.execRegex(text, REGEX.LIST.EMPTY)
	}

	static matchItem(text) {
		return Utils.execRegex(text, REGEX.LIST.ITEM)
	}

	static match(text, isEmpty = false) {
		if (isEmpty) {
			return List.matchEmpty(text)
		}
		return List.matchItem(text)
	}

	constructor(lines, cursor, indent) {
		this.#lines = lines;
		this.#cursor = cursor;
		this.#indent = indent;
		this.#isEmpty = List.testEmpty(lines[cursor]);
		this.#processMeta();

	}

	/**
	 * Finds the end of the list item
	 * Updates the cursor value
	 */
	#findEnd() {
		if (this.#isEmpty) {
			this.#end = this.#cursor + 1;
			return
		}

		let cursor = this.#cursor;
		let nextLine, nextLineIndent, nextNextLine;
		let breakMatch = false;


		do {
			nextLine = this.#lines[++cursor];

			nextLineIndent = Indent.get(nextLine);
			// check for two or more consecutive new lines
			// if we find that, then we know we are at the end of the list item
			nextNextLine = this.#lines[cursor + 1];
			if (
				Newline$1.test({ line: nextLine })
			) {
				if (
					nextNextLine &&
					Newline$1.test({ line: nextNextLine })
				) {
					breakMatch = true;
				} else if (
					Indent.get(nextNextLine) <= this.#indent
				) {
					breakMatch = true;
				}
			}
		} while (
			nextLine !== undefined &&
			!breakMatch &&
			!(
				(
					List.test({ line: nextLine }) ||
					Heading.test({ line: nextLine, nextLine: nextNextLine }) ||
					Quote.test({ line: nextLine })
				) &&
				nextLineIndent <= this.#indent
			)
		)
		this.#end = cursor;
	}

	/**
	 * Processes the list item meta
	 *
	 * The following meta are calculated:
	 * 1. ordered: boolean - if the list item is ordered
	 * 2. identifier: string - the identifier for the list item
	 * 3. check: boolean - if the list item is a checklist item
	 */
	#processMeta() {
		this.#match = List.match(this.#lines[this.#cursor], this.#isEmpty).groups;

		this.#meta.checklist = this.#match.check !== undefined;

		this.#meta.ordered = !!this.#match.count;

		if (this.#match.mark) this.#meta.identifier = this.#match.mark;
	}

	/**
	 * Sets the raw body of the list item
	 */
	#setBody() {
		this.#body = this.#lines.slice(this.#cursor, this.#end);
	}

	/**
	 * Shrinks raw body for the list item
	 */
	#shrinkBody() {
		for (let index = 0; index < this.#body.length; index++) {
			const line = this.#body[index];
			if (index === 0) {
				if (this.#isEmpty) {
					this.#shrunkBody.push("");
				} else {
					this.#shrunkBody.push(this.#match.value);
				}
			} else {
				this.#shrunkBody.push(line);
			}
		}
	}

	/**
	 * Tokenizes the provided lines for the List Item token
	 *
	 * @returns {{cursor: number,  meta: {ordered: boolean, identifier: null, checklist: boolean}, lexer: {count: null, checked: (boolean|null), raw: string, tokens: *, type: string}}}
	 */
	tokenize() {
		this.#findEnd();

		this.#setBody();

		this.#shrinkBody();

		this.#lex = new Lexer$1(this.#shrunkBody, { from: TOKENS.LIST_ITEM });

		return {
			cursor: this.#end - 1,
			meta: this.#meta,
			lexer: {
				type: TOKENS.LIST_ITEM,
				tokens: this.#lex.run(),
				count: this.#match.count || null,
				checked: (this.#meta.checklist) ? this.#match.check === "x" : null,
				raw: this.#body.join("\n")
			}
		}
	}

	/**
	 * Runs HTML parsing for the List token
	 *
	 * @param {Object} lexer - the List lexer
	 *
	 * @returns {string} - the List HTML
	 */
	static parse(lexer) {
		const listTag = (lexer.meta.ordered) ? "ol" : "ul";
		let listBodyHtml = [];
		lexer.items.forEach(listItem => {
			let listItemHtml = "<li>%s</li>";
			const lParser = new Parser(listItem.tokens, { from: TOKENS.LIST });
			if (lexer.meta.checklist) {
				const isChecked = (listItem.checked) ? " checked" : "";
				listItemHtml = listItemHtml. replace(
					"%s",
					"<input type='checkbox'" +
						isChecked +
						">" +
						lParser.run()
				);
			} else {
				listItemHtml = listItemHtml.replace(
					"%s",
					new Parser(listItem.tokens, { from: TOKENS.LIST }).run()
				);
			}
			listBodyHtml.push(listItemHtml);
		});
		return `<${listTag}>${listBodyHtml.join("")}</${listTag}>`
	}

	/**
	 * Runs check if the last and current lexer is of same list type
	 *
	 * Things under check are:
	 * 1. type of the lexers
	 * 2. indentation
	 * 3. is of type checklist
	 * 4. ordered or unordered
	 * 5. identifier of the list item
	 *
	 * @param {Object} baseLexer
	 * @param {Object} lexerToCompare
	 * @param {number} indent
	 *
	 * @returns {boolean}
	 */
	static compareIfTwoListLexerAreOfSameType(baseLexer, lexerToCompare, indent) {
		return (
			baseLexer &&
			baseLexer.type === TOKENS.LIST &&
			baseLexer.indent === indent &&
			baseLexer.meta.checklist === lexerToCompare.meta.checklist &&
			baseLexer.meta.ordered === lexerToCompare.meta.ordered &&
			baseLexer.meta.identifier === lexerToCompare.meta.identifier
		)
	}
}

/**
 * HTML code
 */
class HTML {
	#linkRefs
	#lines
	#cursor
	#indent
	#lex

	static tokenName = TOKENS.HTML

	constructor(lines, cursor, indent, linkRefs) {
		this.#lines = lines;
		this.#cursor = cursor;
		this.#indent = indent;
		this.#linkRefs = linkRefs;
		this.#lex = [];
	}

	/**
	 * @param {string} text
	 *
	 * @returns {boolean}
	 */
	static test(text) {
		return Utils.testRegex(text, REGEX.PARAGRAPH.HTML)
	}

	static testBlock({ lines, cursor }) {
		const lineToParse = lines[cursor];
		return Utils.testRegex(lineToParse, REGEX.HTML)
	}

	tokenize() {
		const regexMatch = Utils.execRegex(this.#lines[this.#cursor], REGEX.HTML);
		this.#lex = {
			type: TOKENS.HTML,
			indent: this.#indent,
			...regexMatch.groups,
			raw: this.#lines[this.#cursor]
		};
		return { lexer: this.#lex, cursor: this.#cursor }
	}

	/**
	 * returns HTML
	 *
	 * @returns {string}
	 */
	static parse(lexer) {
		// if (lexer.tag.toLowerCase() === "a") {
		// 	return `<p>${lexer.raw}</p>`
		// }
		return lexer.raw
	}
}

class Paragraph {
	static tokenName = TOKENS.PARAGRAPH

	/**
	 * Returns a fence object
	 *
	 * @param {Boolean} fence - true if fence, false otherwise
	 * @param {String} ident - identifier, defaults to ""
	 * @param {Number} start - start index, defaults to -1
	 * @param {Number} end - end index, defaults to -1
	 *
	 * @returns {{ident: string, start: number, end: number, fence: boolean}}
	 */
	static fenceObj(fence = false, ident = "", start = -1, end = -1) {
		return {
			fence, ident, start, end
		}
	}

	/**
	 * Determines if the identifier can have a complete fence
	 *
	 * Checks:
	 * 1. If start is greater than the length of the string
	 * 2. If string after start contains the identifier character
	 *
	 * @param str
	 * @param start
	 * @param identifierChar
	 * @returns {boolean}
	 */
	static #fenceSanity(str, start, identifierChar) {
		// if start is greater than the length of the line, immediately return false
		if (start > str.length) return false

		// if no identifier beside the start, immediately return false
		const afterIdentifier = str.substring(start);
		return afterIdentifier.includes(identifierChar)
	}

	/**
	 * Determines if the provided string is fenced from the cursor position
	 *
	 * @param {String} lineToParse - line to parse
	 * @param {Number} cursor - starting position
	 * @param {String} identifier - fence identifier
	 * @param {Boolean} onlyExact - only exact match
	 * @param {Boolean} evenFence - even fence
	 *
	 * @returns {{start: Number, ident: string, end: Number, fence: boolean}}
	 */
	static #isFenced(lineToParse, cursor, identifier, onlyExact=false, evenFence = false) {
		// start from cursor + length of identifier
		const start = cursor + identifier.length;

		const sanity = Paragraph.#fenceSanity(lineToParse, start, identifier[0]);
		if (!sanity) return Paragraph.fenceObj()

		const afterStartStr = lineToParse.slice(start);

		if ((evenFence && identifier.length % 2 === 0)||!evenFence) {
			// if exact identifier behind then do not go for further checks
			const exactEnd = Utils.isExactMatch(afterStartStr, identifier);

			if (exactEnd !== -1) {
				return this.fenceObj(true, identifier, start, start + exactEnd)
			}
		}

		if (!onlyExact) {
			for (let i=start; i >= cursor; i--) {


				const tempIdentifier = lineToParse.substring(cursor, i);

				if (evenFence) {
					if (tempIdentifier.length % 2 !== 0) {
						continue
					}
				}

				const end = Utils.isLooseMatch(afterStartStr, tempIdentifier);

				if (end !== -1) {
					return Paragraph.fenceObj(true, tempIdentifier, start, start + end)
				}
			}
		}

		return Paragraph.fenceObj()
	}


	/**
	 * Link: title, href, tooltip
	 *
	 * If match not found then falsy value is returned
	 * Otherwise, groups and end are returned
	 *
	 * @param {String} lineToParse
	 * @param {Number} cursor
	 * @returns {{found: boolean, groups: null, end: number}|{found: boolean, groups: {[p: string]: string}, end: *}}
	 */
	static #findLink(lineToParse, cursor) {
		const check = lineToParse.substring(cursor);
		if (Utils.testRegex(check, REGEX.PARAGRAPH.LINK)) {
			const match = Utils.execRegex(check, REGEX.PARAGRAPH.LINK);
			return {
				found: true,
				groups: match.groups,
				end: cursor + match[0].length - 1
			}
		} return { found: false, groups: null, end: -1 }
	}

	static #findHtml(lineToParse, cursor) {
		const check = lineToParse.substring(cursor);
		if (Utils.testRegex(check, REGEX.PARAGRAPH.HTML)) {
			const match = Utils.execRegex(check, REGEX.PARAGRAPH.HTML);
			return {
				found: true,
				groups: match.groups,
				end: cursor + match[0].length - 1
			}
		} return { found: false, groups: null, end: -1 }
	}

	/**
	 * Finds link reference in the provided line
	 *
	 * If match not found then falsy value is returned
	 * Otherwise, groups, withText (bool) and end are returned
	 *
	 * @param {String} lineToParse
	 * @param {Number} cursor
	 * @returns {{found: boolean, groups: null, end: number}|{found: boolean, groups: {[p: string]: string}, end: number, withText: boolean}}
	 */
	static #findLinkRef(lineToParse, cursor) {
		const check = lineToParse.substring(cursor);
		let withText = false;
		let match;

		if (Utils.testRegex(check, REGEX.PARAGRAPH.REF_LINK)) {
			// check if link ref with text
			if (Utils.testRegex(check, REGEX.LINK_REF.WITH_TEXT)) {
				withText = true;
				match = Utils.execRegex(check, REGEX.LINK_REF.WITH_TEXT);
			} else {
				match = Utils.execRegex(check, REGEX.LINK_REF.WITHOUT_TEXT);
			}

			return {
				found: true,
				withText,
				groups: match.groups,
				end: cursor + match[0].length - 1
			}
		} return { found: false, groups: null, end: -1 }
	}


	/**
	 * Finds image in the provided line
	 *
	 * If match not found then falsy value is returned
	 * Otherwise, groups and end are returned
	 *
	 * @param {String} lineToParse
	 * @param {Number} cursor
	 *
	 * @returns {{found: boolean, groups: {[p: string]: string}, end: number}|{found: boolean, groups: null, end: number}}
	 */
	static #findImage(lineToParse, cursor) {
		const check = lineToParse.substring(cursor);
		if (Utils.testRegex(check, REGEX.PARAGRAPH.IMAGE)) {
			const match = Utils.execRegex(check, REGEX.PARAGRAPH.IMAGE);
			return {
				found: true,
				groups: match.groups,
				end: cursor + match[0].length - 1
			}
		} return { found: false, groups: null, end: -1 }
	}

	/**
	 * Tokenize emphasis using the identifiers
	 *
	 * 1. Bold: **|__ fence (even)
	 * 2. Italics: *|_ fence (odd)
	 * 3. Code: ` fence (exact)
	 * 4. Underline: ++ fence (even)
	 * 5. Strike: -- fence (even)
	 * 6. Links: [text](url "title")
	 * 					"title" is optional
	 * 7. Image: ![text](url "title" 50 50)
   * 					"title" 50 50 are optional
	 *
	 *
	 * @param {String} lineToParse
	 * @param {Array} linkRefs
	 *
	 * @returns {*[]}
	 */
	static #findEmphasis(lineToParse, linkRefs) {
		let identifier;
		const tokens = [];

		function runCheckForTextBeforeStart(start, cursor, ident) {
			const lastToken = tokens[tokens.length - 1];
			if (start > cursor + ident.length) {
				const text = lineToParse.substring(cursor, start - ident.length);
				if (lastToken && lastToken.type === TOKENS.TEXT) {
					lastToken.raw += text;
					lastToken.value += text;
				} else {
					tokens.push({
						type: TOKENS.TEXT,
						raw: text,
						value: text
					});
				}
			}
		}

		for (let cursor=0; cursor<lineToParse.length; cursor++) {
			const currChar = lineToParse[cursor];
			const prevChar = lineToParse[cursor-1] || null;
			const nextChar = lineToParse[cursor+1] || null;
			const lastToken = tokens[tokens.length - 1];

			let escape = false;

			if (prevChar && prevChar === "\\") escape = true;

			if (!escape && (currChar === "*" || currChar === "_")) {
				identifier = Utils.findConsecutive(lineToParse, cursor, currChar);

				const { fence, ident, start, end } = Paragraph.#isFenced(lineToParse, cursor, identifier);

				if (fence) {
					// grab the text before the fence
					runCheckForTextBeforeStart(start, cursor, ident);

					const v = lineToParse.slice(start, end);
					tokens.push({
						type: (ident.length % 2 === 0)
							? TOKENS.BOLD
							: TOKENS.ITALIC,
						raw: `${ident}${v}${ident}`,
						tokens: Paragraph.#findEmphasis(v, linkRefs)
					});
					cursor = end + ident.length - 1;
					continue
				}
			}
			else if (!escape && currChar === "`") {
				identifier = Utils.findConsecutive(lineToParse, cursor, "`");

				const { fence, ident, start, end } = Paragraph.#isFenced(lineToParse, cursor, identifier, true);

				if (fence) {
					const value = lineToParse.slice(start, end);
					if (value.length > 0) {
						tokens.push({
							type: TOKENS.CODE,
							raw: `${ident}${value}${ident}`,
							// TIP: no need to waste time escaping it again
							// because, the code token value is already escaped here
							value: value.trim()
						});
						cursor = end + ident.length - 1;
						continue
					}
				}
			}
			else if (!escape && ["~", "+"].includes(currChar)) {
				// underline and strike
				if (nextChar && nextChar === currChar) {
					identifier = Utils.findConsecutive(lineToParse, cursor, currChar);

					const { fence, ident, start, end } = Paragraph.#isFenced(lineToParse, cursor, identifier, false, true);

					if (fence) {
						runCheckForTextBeforeStart(start, cursor, ident);

						const v = lineToParse.slice(start, end);
						tokens.push({
							type: (currChar === "+") ? TOKENS.UNDERLINE: TOKENS.STRIKE_THROUGH,
							raw: `${ident}${v}${ident}`,
							tokens: Paragraph.#findEmphasis(v, linkRefs)
						});
						cursor = end + ident.length - 1;
						continue
					}
				}
			}
			else if (!escape && currChar === "[") {
				// link
				const linkMatch = Paragraph.#findLink(lineToParse, cursor);

				if (linkMatch.found) {
					tokens.push({
						type: TOKENS.LINK,
						raw: lineToParse.slice(cursor, linkMatch.end + 1),
						tokens: {
							title: {
								raw: linkMatch.groups.text,
								tokens: Paragraph.#findEmphasis(linkMatch.groups.text, linkRefs)
							},
							href: linkMatch.groups.href,
							tooltip: linkMatch.groups.title
						}
					});
					cursor = linkMatch.end;
					continue
				}

				// link reference
				if (linkRefs.length > 0) {
					const linkRefMatch = Paragraph.#findLinkRef(lineToParse, cursor);
					if (linkRefMatch.found) {

						// if the found reference is in the list of references, add it to the tokens
						const ref = linkRefs.find(r => r.text === linkRefMatch.groups.ref);

						if (ref) {
							const rawTitle = (linkRefMatch.withText) ? linkRefMatch.groups.text : ref.text;

							tokens.push({
								type: TOKENS.LINK,
								raw: lineToParse.slice(cursor, linkRefMatch.end + 1),
								tokens: {
									title: {
										raw: rawTitle,
										tokens: Paragraph.#findEmphasis(rawTitle, linkRefs)
									},
									href: ref.href,
									tooltip: ref.title
								}
							});
							cursor = linkRefMatch.end;
							continue
						}
					}
				}
			}
			else if (!escape && currChar === "!") {
				// image parsing
				const imageMatch = Paragraph.#findImage(lineToParse, cursor);
				if (imageMatch.found) {
					tokens.push({
						type: TOKENS.IMAGE,
						raw: lineToParse.slice(cursor, imageMatch.end + 1),
						tokens: imageMatch.groups
					});
					cursor = imageMatch.end;
					continue
				}
				// TODO: image reference
			}
			else if (!escape && currChar === "<") {
				const htmlMatch = Paragraph.#findHtml(lineToParse, cursor);
				if (htmlMatch.found) {
					tokens.push({
						type: TOKENS.HTML,
						raw: lineToParse.slice(cursor, htmlMatch.end + 1),
						tokens: {
							tag: htmlMatch.groups?.tag || htmlMatch.groups?.endTag,
							attributes: htmlMatch.groups.attrs?.trim(),
							isEndTag: !! htmlMatch.groups?.endTag
						}
					});
					cursor = htmlMatch.end;
					continue
				}
			}

			// otherwise a normal text
			if (lastToken && lastToken.type === TOKENS.TEXT) {
				lastToken.raw += currChar;
				lastToken.value += currChar;
			} else {
				// a normal text
				tokens.push({
					type: TOKENS.TEXT,
					raw: currChar,
					value: currChar
				});
			}
		}
		return tokens
	}

	/**
	 * Paragraph Tokenization
	 * Tokenizes a line of text into emphasis tokens
	 *
	 * @param {String} lineToParse
	 * @param {Array} linkRefs
	 *
	 * @returns {*[]}
	 */
	static tokenize(lineToParse, linkRefs) {
		return Paragraph.#findEmphasis(lineToParse, linkRefs)
	}

	static parse(lexer) {
		let parsed = "";
		lexer.tokens.forEach(token => {
			if (token.type === TOKENS.BOLD) {
				parsed += `<strong>${Paragraph.parse(token)}</strong>`;
			} else if (token.type === TOKENS.ITALIC) {
				parsed += `<em>${Paragraph.parse(token)}</em>`;
			} else if (token.type === TOKENS.CODE) {
				token.value = Esc.unEscape(token.value);
				parsed += `<code>${Esc.everything(token.value)}</code>`;
			}else if (token.type === TOKENS.STRIKE_THROUGH) {
				parsed += `<s>${Paragraph.parse(token)}</s>`;
			} else if (token.type === TOKENS.LINK) {
				const linkTokens = token.tokens;
				let linkTag = `<a href="${linkTokens.href}"` +
						(linkTokens.tooltip ? ` title="${linkTokens.tooltip}"` : "") +
						">" +
						Paragraph.parse(linkTokens.title) +
						"</a>";

				parsed += linkTag;
			} else if (token.type === TOKENS.UNDERLINE) {
				parsed += `<u>${Paragraph.parse(token)}</u>`;
			} else if (token.type === TOKENS.IMAGE) {
				const imgTokens = token.tokens;
				let imgTag = `<img src="${imgTokens.href}"` +
						(imgTokens.alt !== undefined ? ` alt="${imgTokens.alt}"` : "") +
						(imgTokens.title !== undefined ? ` title="${imgTokens.title}"` : "") +
						(imgTokens.width !== undefined ? ` width="${imgTokens.width}"` : "") +
						(imgTokens.height !== undefined ? ` height="${imgTokens.height}"` : "") +
						">";
				parsed += imgTag;
			} else if (token.type === TOKENS.HTML) {
				parsed += token.raw;
			} else {
				const escaped = Esc.nonTags(token.value);
				const unescaped = Esc.unEscape(escaped);
				parsed += unescaped;
			}
		});
		return parsed
	}
}

var Paragraph$1 = Paragraph;

class FrontMatter {
	#lines
	#endLine
	#body
	#value = {}

	static tokenName = TOKENS.FRONT_MATTER

	constructor(lines) {
		this.#lines = lines;
		this.findEnd();
	}

	static test(lines) {
		if (Utils.testRegex(lines[0], REGEX.FRONT_MATTER.BOUNDARY)) {
			for (let i = 1; i < lines.length; i++) {
				const line = lines[i];
				if (Utils.testRegex(line, REGEX.FRONT_MATTER.BOUNDARY)) {
					return true
				}
				if (!Utils.testRegex(line, REGEX.FRONT_MATTER.ENTRY)) {
					return false
				}
			}
		}
		return false
	}

	findEnd() {
		for (let i = 1; i < this.#lines.length; i++) {
			if (Utils.testRegex(this.#lines[i], REGEX.FRONT_MATTER.BOUNDARY)) {
				this.#endLine = i + 1;
			}
		}
		this.#body = this.#lines.slice(1, this.#endLine - 1);
	}

	removeFrontMatterFromGivenLines() {
		return this.#lines.slice(this.#endLine + 1)
	}

	getValue() {
		for (let i = 0; i < this.#body.length; i++) {
			const line = this.#body[i];
			if (Utils.testRegex(line, REGEX.FRONT_MATTER.ENTRY)) {
				const match = Utils.execRegex(line, REGEX.FRONT_MATTER.ENTRY);
				if (match) {
					let keyValue = match.groups.value;
					if (["true", "false"].includes(keyValue.toLowerCase())) {
						keyValue = keyValue.toLowerCase() === "true";
					} else if (REGEX.NUMBER.test(keyValue)) {
						keyValue = parseInt(keyValue);
					} else if (REGEX.NUMBER_WITH_DECIMAL.test(keyValue)) {
						keyValue = parseFloat(keyValue);
					} else if (REGEX.BIG_BRACKETED.test(keyValue) || REGEX.CURLY_BRACKETED.test(keyValue)) {
						try {
							keyValue = JSON.parse(keyValue);
						} catch (e) {
							// do nothing
						}
					}
					this.#value[match.groups.key] = keyValue;
				}
			}
		}
		return this.#value
	}
}

class Newline {
	static tokenName = TOKENS.NEW_LINE

	static test({ line }) {
		if (typeof line !== "string") return false
		return ["", "\n"].includes(line.trim())
	}

	/**
	 * returns HTML for a newline
	 *
	 * @returns {string}
	 */
	static parse() {
		return "<br>"
	}
}

var Newline$1 = Newline;

const Parsers = {
	Table, Image, Comment, HrLine, CodeBlock,
	Quote, Heading, List, HTML, Paragraph: Paragraph$1
};

class Lexer {
	#cursor
	#lines
	#lexerData
	#currLine
	#nextLine
	#currLineIndent
	#currLineRawIndent
	#lastLexerItem
	#lexerLengthBefore
	#fromToken
	#linkRefs = []
	#frontMatter
	#config

	constructor(lines, { from = null, config= {} } = {}) {
		this.#lines = lines;
		this.#lexerData = [];
		this.#fromToken = from;
		this.#cursor = 0;
		this.#config = config;
	}

	#runCurrLineLexer() {
		const context = {
			line: this.#currLine,
			nextLine: this.#nextLine,
			lines: this.#lines,
			cursor: this.#cursor,
			indent: this.#currLineIndent,
			lastLexer: this.#lastLexerItem,
			fromToken: this.#fromToken
		};

		if (Newline$1.test(context)) return this.#runNewLineLexer()

		if (Heading.test(context)) return this.#runHeadingLexer()

		if (HrLine.test(context)) return this.#runHrLineLexer()

		if (Comment.test(context)) return this.#runCommentLexer()

		if (Image.test(context)) return this.#runImageLexer()

		if (Quote.test(context)) return this.#runQuoteLexer()

		if (List.test(context)) return this.#runListLexer()

		if (Table.test(context)) return this.#runTableLexer()

		if (HTML.testBlock(context)) return this.#runHTMLLexer()

		if (CodeBlock.test(context)) return this.#runCodeBlockLexer()

		// otherwise, it is a paragraph
		return this.#runParagraphLexer()
	}

	#runNewLineLexer() {
		// cannot be added at the top of the content
		if (this.#lexerLengthBefore === 0) return true
		// if there are multiple new lines in a row,
		// only single new line is added to the lexerContent
		if (this.#lastLexerItem.type !== TOKENS.NEW_LINE) {
			this.#lexerData.push({
				type: TOKENS.NEW_LINE
			});
		}
	}

	#runHrLineLexer() {
		// if (this.#lastLexerItem && this.#lastLexerItem.type === TOKENS.HR_LINE) return true
		this.#lexerData.push({
			type: TOKENS.HR_LINE
		});
	}

	#runCodeBlockLexer() {
		const cbTokenizer = new CodeBlock(
			this.#lines,
			this.#cursor,
			this.#currLineIndent,
			this.#currLineRawIndent
		);

		const cbTokens = cbTokenizer.tokenize();

		this.#lexerData.push(cbTokens.lexer);

		// skip the lines that were parsed
		this.#cursor = cbTokens.cursor;
	}

	#runTableLexer() {
		const tableTokenizer = new Table(
			this.#lines,
			this.#cursor,
			this.#currLineIndent,
			this.#linkRefs
		);
		const tableTokens = tableTokenizer.tokenize();

		this.#lexerData.push(tableTokens.lexer);

		this.#cursor = tableTokens.cursor;
	}

	#runHTMLLexer() {
		const htmlTokenizer = new HTML(
			this.#lines,
			this.#cursor,
			this.#currLineIndent,
			this.#linkRefs
		);
		const htmlTokens = htmlTokenizer.tokenize();

		this.#lexerData.push(htmlTokens.lexer);

		this.#cursor = htmlTokens.cursor;
	}

	#runListLexer() {
		const list = new List(
			this.#lines,
			this.#cursor,
			this.#currLineIndent,
			this.#fromToken
		);
		const listTokens = list.tokenize();


		this.#cursor = listTokens.cursor;

		// case 1: if the last lexer is a list with same context,
		// then merge the list items into the last lexer items
		if (
			List.compareIfTwoListLexerAreOfSameType(this.#lastLexerItem, listTokens, this.#currLineIndent)
		) {
			this.#lastLexerItem.items.push(listTokens.lexer);
			this.#lastLexerItem.raw += `\n${listTokens.lexer.raw}`;
			return
		}

		// case 2: if the last lexer is a newline and the lexer before that is a list with same context,
		// then merge the list items into the last lexer items
		const lastLastLexerItem = this.#lexerData[this.#lexerData.length - 2] || false;

		if (
			this.#lastLexerItem &&
			this.#lastLexerItem.type === TOKENS.NEW_LINE &&
			List.compareIfTwoListLexerAreOfSameType(lastLastLexerItem, listTokens, this.#currLineIndent)
		) {
			// remove last newline from the lexer content
			this.#lexerData.pop();
			// add the list to the last lexer item
			const lastLexerItem = this.#lexerData.at(-1);
			// lastLexerItem.items.push(newline)
			lastLexerItem.items.push(listTokens.lexer);
			lastLexerItem.raw += `\n${listTokens.lexer.raw}`;
			return
		}

		this.#lexerData.push({
			type: TOKENS.LIST,
			indent: this.#currLineIndent,
			meta: listTokens.meta,
			items: [listTokens.lexer],
			raw: listTokens.lexer.raw
		});
	}

	#runQuoteLexer() {
		const quoteTokenizer = new Quote(this.#lines, this.#cursor);
		const quoteTokens = quoteTokenizer.tokenize();
		this.#cursor = quoteTokens.cursor;

		this.#lexerData.push({
			indent: this.#currLineIndent,
			...quoteTokens.lexer
		});
	}

	#runHeadingLexer() {
		const hTokenizer = new Heading(this.#currLine, this.#nextLine);
		const hTokens = hTokenizer.tokenize();

		if (hTokens.setext) {
			this.#cursor++;
		}

		this.#lexerData.push({
			type: TOKENS.HEADING,
			indent: this.#currLineIndent,
			...hTokens,
			tokens: Paragraph$1.tokenize(hTokens.value, this.#linkRefs)
		});
	}

	#runCommentLexer() {
		this.#lexerData.push({
			type: TOKENS.COMMENT,
			indent: this.#currLineIndent,
			...Comment.tokenize(this.#currLine),
			raw: this.#currLine
		});
	}

	#runImageLexer() {
		this.#lexerData.push({
			type: TOKENS.IMAGE,
			indent: this.#currLineIndent,
			...Image.tokenize(this.#currLine),
			raw: this.#currLine
		});
	}

	#runParagraphLexer() {
		if (
			this.#lastLexerItem &&
			this.#lastLexerItem.type === TOKENS.PARAGRAPH &&
			this.#currLineIndent >= this.#lastLexerItem.indent
		) {
			// if the last line has 2 or more spaces at the end,
			// then a line break is added to the last line
			// otherwise, the line is added to the last line
			if (this.#lastLexerItem.raw.endsWith("  ")) {
				this.#lastLexerItem.value = this.#lastLexerItem.value.trimEnd() + "<br>";
			}
			this.#lastLexerItem.raw += `\n${this.#currLine}`;
			this.#lastLexerItem.value += ` ${this.#currLine}`;
			this.#lastLexerItem.tokens = Paragraph$1.tokenize(this.#lastLexerItem.value, this.#linkRefs);
		} else {
			this.#lexerData.push({
				type: TOKENS.PARAGRAPH,
				indent: this.#currLineIndent,
				tokens: Paragraph$1.tokenize(this.#currLine, this.#linkRefs),
				raw: this.#currLine,
				value: this.#currLine
			});
		}
	}

	#checkForLinkRefs() {
		for (this.#cursor = 0; this.#cursor < this.#lines.length; this.#cursor++) {
			const line = this.#lines[this.#cursor];
			if (Utils.testRegex(line, REGEX.LINK_REF.DECLARATION)) {
				this.#linkRefs.push(Utils.execRegex(line, REGEX.LINK_REF.DECLARATION).groups);
				// now remove the current line from the lines array
				this.#lines.splice(this.#cursor, 1);
				// and decrement the cursor
				this.#cursor--;
			}
		}
	}

	#runPrep() {
		this.#currLine = this.#lines[this.#cursor];
		this.#nextLine = this.#lines[this.#cursor + 1];
		this.#lexerLengthBefore = this.#lexerData.length;
		this.#lastLexerItem = this.#lexerData[this.#lexerLengthBefore - 1] || null;
		this.#currLineRawIndent = Indent.raw(this.#currLine);
		this.#currLineIndent = Indent.calc(this.#currLineRawIndent);
	}

	#skipFrontMatter() {
		if (FrontMatter.test(this.#lines)) {
			this.#frontMatter = new FrontMatter(this.#lines);
			this.#lines = this.#frontMatter.removeFrontMatterFromGivenLines();
			this.#cursor = 0;
		}
	}

	getFrontMatter() {
		if (FrontMatter.test(this.#lines)) {
			this.#frontMatter = new FrontMatter(this.#lines);
			return this.#frontMatter.getValue()
		} else {
			return {}
		}
	}

	run() {
		this.#skipFrontMatter();
		this.#checkForLinkRefs();

		for (this.#cursor = 0; this.#cursor < this.#lines.length; this.#cursor++) {
			this.#runPrep();
			this.#runCurrLineLexer();
		}

		return this.#lexerData
	}
}

var Lexer$1 = Lexer;

class HtmlMark {
	config = {}

	constructor(config = {}) {
		this.config.indent = config.indent || 4;
		this.config.highlightFn = config.highlightFn || null;
		this.config.useLinkRefs = config.useLinkRefs || false;
	}

	tokenize(str) {
		if (typeof str !== "string") throw new Error("Input must be a string")
		const lexer = new Lexer$1(str.split("\n"), { config: this.config });
		return lexer.run()
	}

	parse(str) {
		if (typeof str !== "string") throw new Error("Input must be a string")
		const lex = this.tokenize(str);
		const parser = new Parser(lex, { config: this.config });
		return parser.run()
	}

	getFrontMatter(str) {
		if (typeof str !== "string") throw new Error("Input must be a string")
		const lexer = new Lexer$1(str.split("\n"));
		return lexer.getFrontMatter()
	}
}

export { HtmlMark as default };
//# sourceMappingURL=htmlmark.esm.js.map
